{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project -- Recommendations with IBM\n",
    "\n",
    "\n",
    "## Introduction\n",
    "> Being recommended by various types of products or services when we browse on the social media or just would like to reserve a room in Airbnb becomes an usual scenario as a part of surfing the Internet. While sometimes it's annoying when advertisments are frequently jumping out, it's also provide users novelty and serendipity when the recommendations spot on their requests. The mechanism behind the recommendation engines is explored, and the interactions between users and articles is also analyzed in this project. The datasets are provided by Udacity and include two parts: <br>\n",
    "\n",
    "> 1. Interaction of users and articles: The dataset includes article id, title of article, and email <br>\n",
    "> 2. Information of articles: It contains information such as id, descriptions, status, full name of articles <br> \n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "II. [Rank Based Recommendations](#Rank)<br>\n",
    "III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "VI. [Conclusion](#conclusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/johnma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/johnma/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/johnma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import project_tests as t\n",
    "import pickle\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Better display for Jupyter notebooks\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "%config InlineBachend.figure_format = 'retina'\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('/Users/johnma/Desktop/Udacity_Data Scientist/Project folder/Project 3_Recommendation Engines/Data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('/Users/johnma/Desktop/Udacity_Data Scientist/Project folder/Project 3_Recommendation Engines/Data/articles_community.csv')\n",
    "\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>PouchDB-find is a new API and syntax that allo...</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>A look under the covers of PouchDB-find</td>\n",
       "      <td>Live</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>We compare discriminative and generative learn...</td>\n",
       "      <td>A comparison of logistic regression and naive ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Essays about data, building products and boots...</td>\n",
       "      <td>In order to demystify some of the magic behind...</td>\n",
       "      <td>What I Learned Implementing a Classifier from ...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn how to use IBM dashDB as data store for ...</td>\n",
       "      <td>Use dashDB with Spark</td>\n",
       "      <td>Live</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * H...</td>\n",
       "      <td>Once you get used to developing in a Notebook ...</td>\n",
       "      <td>Jupyter Notebooks with Scala, Python, or R Ker...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_body  \\\n",
       "1051  PouchDB-find is a new API and syntax that allo...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  Essays about data, building products and boots...   \n",
       "1054                                                NaN   \n",
       "1055  Homepage Follow Sign in / Sign up Homepage * H...   \n",
       "\n",
       "                                        doc_description  \\\n",
       "1051  PouchDB uses MapReduce as its default search m...   \n",
       "1052  We compare discriminative and generative learn...   \n",
       "1053  In order to demystify some of the magic behind...   \n",
       "1054  Learn how to use IBM dashDB as data store for ...   \n",
       "1055  Once you get used to developing in a Notebook ...   \n",
       "\n",
       "                                          doc_full_name doc_status  article_id  \n",
       "1051            A look under the covers of PouchDB-find       Live        1046  \n",
       "1052  A comparison of logistic regression and naive ...       Live        1047  \n",
       "1053  What I Learned Implementing a Classifier from ...       Live        1048  \n",
       "1054                              Use dashDB with Spark       Live        1049  \n",
       "1055  Jupyter Notebooks with Scala, Python, or R Ker...       Live        1050  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45993 entries, 0 to 45992\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   article_id  45993 non-null  float64\n",
      " 1   title       45993 non-null  object \n",
      " 2   email       45976 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "-----------------\n",
      "Rows with missing items are listed below\n",
      "-----------------\n",
      "article_id     0\n",
      "title          0\n",
      "email         17\n",
      "dtype: int64\n",
      "-----------------\n",
      "Duplicated rows are listed below\n",
      "-----------------\n",
      "12311\n"
     ]
    }
   ],
   "source": [
    "# Overview of df\n",
    "print (df.info())\n",
    "print ('-----------------')\n",
    "print ('Rows with missing items are listed below')\n",
    "print ('-----------------')\n",
    "print (df.isnull().sum())\n",
    "print ('-----------------')\n",
    "print ('Duplicated rows are listed below')\n",
    "print ('-----------------')\n",
    "print (df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1056 entries, 0 to 1055\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   doc_body         1042 non-null   object\n",
      " 1   doc_description  1053 non-null   object\n",
      " 2   doc_full_name    1056 non-null   object\n",
      " 3   doc_status       1056 non-null   object\n",
      " 4   article_id       1056 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 41.4+ KB\n",
      "None\n",
      "-----------------\n",
      "Rows with missing items are listed below\n",
      "-----------------\n",
      "doc_body           14\n",
      "doc_description     3\n",
      "doc_full_name       0\n",
      "doc_status          0\n",
      "article_id          0\n",
      "dtype: int64\n",
      "-----------------\n",
      "Duplicated rows are listed below\n",
      "-----------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Overview of df_content\n",
    "print (df_content.info())\n",
    "print ('-----------------')\n",
    "print ('Rows with missing items are listed below')\n",
    "print ('-----------------')\n",
    "print (df_content.isnull().sum())\n",
    "print ('-----------------')\n",
    "print ('Duplicated rows are listed below')\n",
    "print ('-----------------')\n",
    "print (df_content.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Data \n",
    "\n",
    "> 1. dtype of 'article_id' is flt\n",
    "> 2. In the content of email & doc_body & doc_description, few rows with missing values are found\n",
    "> 3. There are 12311 duplicated rows in df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "Use the dictionary and cells below to provide some insight into the descriptive statistics of the data.\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email\n",
       "0000b6387a0366322d7fbfc6434af145adf7fed1    13\n",
       "001055fc0bb67f71e8fa17002342b256a30254cd     4\n",
       "00148e4911c7e04eeff8def7bbbdaf1c59c2c621     3\n",
       "001a852ecbd6cc12ab77a785efa137b2646505fe     6\n",
       "001fc95b90da5c3cb12c501d201a915e4f093290     2\n",
       "                                            ..\n",
       "ffc6cfa435937ca0df967b44e9178439d04e3537     2\n",
       "ffc96f8fbb35aac4cb0029332b0fc78e7766bb5d     4\n",
       "ffe3d0543c9046d35c2ee3724ea9d774dff98a32    32\n",
       "fff9fc3ec67bd18ed57a34ed1e67410942c4cd81    10\n",
       "fffb93a166547448a0ff0232558118d59395fecd    13\n",
       "Name: article_id, Length: 5148, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since each email address represents a unique user,\n",
    "# groupby function is used to demonstrate the interaction between user and articles\n",
    "data = df.groupby('email')['article_id'].count()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1416\n",
       "2      694\n",
       "3      485\n",
       "4      351\n",
       "5      277\n",
       "6      228\n",
       "7      182\n",
       "8      156\n",
       "10     124\n",
       "9      115\n",
       "Name: article_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median number of user article is 3.0\n",
      "The maximum number of user-article interactions is 364\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "# 50% of individuals interact with \"3\" number of articles or fewer.\n",
    "median_val = data.median()\n",
    "print ('The median number of user article is', median_val)\n",
    "\n",
    "# The maximum number of user-article interactions by any 1 user is 364.\n",
    "max_views_by_user = data.max()\n",
    "print ('The maximum number of user-article interactions is', max_views_by_user)\n",
    "\n",
    "# plot the distribution of articles & users\n",
    "plt.figure(figsize=(15,8))\n",
    "base_color = sb.color_palette()[0]\n",
    "plt.hist(data, bins = 500, ec=base_color)\n",
    "plt.vlines(x=median_val, ymin=0, ymax=1450, color='red')\n",
    "plt.xlabel('Number of Users', fontsize=12)\n",
    "plt.ylabel('Number of Articles', fontsize=12)\n",
    "plt.title('Distribution of Articles & Users')\n",
    "plt.annotate(xy=(median_val, 1200), text=f'Median: {median_val}')\n",
    "#plt.annotate(xy=(median, 2500), s=f'Median: {median}');\n",
    "plt.savefig('Distribution of Article & user.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distriubion of articles and users is visualized as above. Clearly, the distriubtion is quite right-skewed, and the frequecies of the top 3 popular articles are 1416, 694, and 485 times respectively. Also, 50% of indivisuals interact with 3 articles or fewer while the maximum number of user-article interaction by any one user is 364 times**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and explore duplicate articles -- 5 duplicates are found based on article_id\n",
    "df_content.duplicated(subset='article_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "df_content.drop_duplicates(subset='article_id', keep='first', inplace=True)\n",
    "\n",
    "# Check whether the duplicates are removed\n",
    "df_content.duplicated(subset='article_id').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 duplicates are found, and the duplicated rows are also removed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of unique articles that have at least one interaction\n",
    "unique_articles = len (pd.crosstab(df['email'], df['article_id']).sum())\n",
    "\n",
    "# The number of unique articles on the IBM platform\n",
    "total_articles = df_content['article_id'].nunique() \n",
    "\n",
    "# The number of unique users\n",
    "unique_users = df['email'].nunique() \n",
    "\n",
    "# The number of user-article interactions\n",
    "user_article_interactions = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. The number of unique articles that have an interaction with a user is 714\n",
      "b. The number of unique articles in the dataset is 1051\n",
      "c. The number of unique users in the dataset is 5148\n",
      "d. The number of user-article interactions in the dataset is 45993\n"
     ]
    }
   ],
   "source": [
    "print ('a. The number of unique articles that have an interaction with a user is', unique_articles)\n",
    "print ('b. The number of unique articles in the dataset is', total_articles)\n",
    "print ('c. The number of unique users in the dataset is', unique_users)\n",
    "print ('d. The number of user-article interactions in the dataset is', user_article_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "1429.0    937\n",
       "1330.0    927\n",
       "1431.0    671\n",
       "1427.0    643\n",
       "1364.0    627\n",
       "1314.0    614\n",
       "1293.0    572\n",
       "1170.0    565\n",
       "1162.0    512\n",
       "1304.0    483\n",
       "Name: email, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 reivewed article id with number of views\n",
    "df.groupby('article_id')['email'].count().sort_values(ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ID of the most viewd article is 1429.0\n",
      "The max number of viewed is 937\n"
     ]
    }
   ],
   "source": [
    "# The most viewed article in the dataset as a string with one value following the decimal \n",
    "most_viewed_article_id = str (df.groupby('article_id')['email'].count().sort_values(ascending=False).index[:1][0])\n",
    "\n",
    "#The most viewed article in the dataset was viewed how many times?\n",
    "max_views = df.groupby('article_id')['email'].count().sort_values(ascending=False).values[:1][0]\n",
    "\n",
    "print ('The ID of the most viewd article is', most_viewed_article_id)\n",
    "print ('The max number of viewed is', max_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "1429.0    937\n",
       "1330.0    927\n",
       "1431.0    671\n",
       "1427.0    643\n",
       "1364.0    627\n",
       "1314.0    614\n",
       "1293.0    572\n",
       "1170.0    565\n",
       "1162.0    512\n",
       "1304.0    483\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('article_id')['title'].count().sort_values(ascending=False).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_articles(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    top_articles = df.groupby('title')['article_id'].count().sort_values(ascending=False).index[:n]\n",
    "    \n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    top_articles = df.groupby('article_id')['title'].count().sort_values(ascending=False).index[:n]\n",
    " \n",
    "    return top_articles # Return the top article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['use deep learning for image classification',\n",
      "       'insights from new york car accident reports',\n",
      "       'visualize car data with brunel',\n",
      "       'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
      "       'predicting churn with the spss random tree algorithm',\n",
      "       'healthcare python streaming application demo',\n",
      "       'finding optimal locations of new store using decision optimization',\n",
      "       'apache spark lab, part 1: basic concepts',\n",
      "       'analyze energy consumption in buildings',\n",
      "       'gosales transactions for logistic regression model'],\n",
      "      dtype='object', name='title')\n",
      "Float64Index([1429.0, 1330.0, 1431.0, 1427.0, 1364.0, 1314.0, 1293.0, 1170.0,\n",
      "              1162.0, 1304.0],\n",
      "             dtype='float64', name='article_id')\n"
     ]
    }
   ],
   "source": [
    "print(get_top_articles(10))\n",
    "print(get_top_article_ids(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Use function of crosstab to create matrix\n",
    "    user_item = pd.crosstab(df['user_id'], df['article_id'])\n",
    "    \n",
    "    # Assign a value of 1 to all the elements in the user-item matrix that satisfy the condition user_item > 0\n",
    "    user_item[user_item > 0] = 1\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar). Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_users(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user by using dot function\n",
    "    dot_prod_user = user_item.dot(user_item.loc[user_id])\n",
    "\n",
    "    # sort by similarity\n",
    "    similarities = dot_prod_user.sort_values(ascending = False)\n",
    "\n",
    "    # create list of just the user ids\n",
    "    most_similar_users = list (similarities.index)\n",
    "    \n",
    "    # remove the own user's id\n",
    "    most_similar_users.remove(user_id)\n",
    "    \n",
    " \n",
    "    return most_similar_users # return a list of the users in order from most to least similar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 3870, 131, 4201, 46, 5041]\n",
      "The 5 most similar users to user 3933 are: [1, 23, 3782, 203, 4459]\n",
      "The 3 most similar users to user 46 are: [4201, 3782, 23]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Complete the functions below to return the articles you would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    df.article_id = df.article_id.astype(str) # Convert dtype of article_id into str\n",
    "    article_names = df[df['article_id'].isin(article_ids)]['title'].unique().tolist()\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    user = user_item.loc[user_id]\n",
    "    article_ids = user [user == 1].index.tolist() # List for user series mapping with user_item as 1\n",
    "    article_ids = [str (article_id) for article_id in article_ids] # Convert article_ids into str\n",
    "    \n",
    "    article_names = get_article_names(article_ids, df)\n",
    "    \n",
    " \n",
    "    return article_ids, article_names # return the ids and names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    similar_user_id = find_similar_users(user_id)\n",
    "    user_article_id = get_user_articles(similar_user_id)[0]\n",
    "    recs = []\n",
    "    for user in similar_user_id:\n",
    "        user_article_id = get_user_articles(user)[0] # get the list of article ids and names of each user\n",
    "        for article_id in rec_article_id:\n",
    "            if (article_id in rec_ariticle_id) or (article_id in recs):\n",
    "                continue \n",
    "            \n",
    "            else:\n",
    "                if len (recommendation_lst) == m:\n",
    "                    return recs\n",
    "                \n",
    "                else:\n",
    "                    recs.append(article_id) # append all articles that are left to the recommendation list\n",
    "                  \n",
    "    return recs # return your recommendations for this user_id    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user - if a u\n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    # compute similarity of each user to the provided user_id \n",
    "    similarity_dict = {}\n",
    "    \n",
    "    for index, col in user_item.iterrows():\n",
    "        similarity = np.dot(user_item.loc[user_id], user_item.loc[index])\n",
    "        similarity_dict[index] = similarity   \n",
    "        similarity_dict_df = pd.DataFrame.from_dict(similarity_dict, orient = 'index')\n",
    "    \n",
    "    similarity_dict_df.columns = ['similarity']\n",
    "    \n",
    "    # compute article interactions of each user to the provided user_id    \n",
    "    article_interactions_df = df.groupby('user_id').count()['article_id'].to_frame()\n",
    "    article_interactions_df.columns = ['# of article interactions']\n",
    "    \n",
    "    # concatenating the 2 series (similarity series, article interactions series) into 1 dataframe\n",
    "    neighbors_df = pd.concat([similarity_dict_df, article_interactions_df], axis=1)\n",
    "    neighbors_df['neighbor id'] = neighbors_df.index\n",
    "    neighbors_df.drop([user_id], inplace=True) \n",
    "    neighbors_df = neighbors_df[['neighbor id', 'similarity', '# of article interactions']].sort_values(by=['similarity', '# of article interactions'], ascending=False)\n",
    "    \n",
    "    \n",
    "    return neighbors_df # Return the dataframe specified in the doc_string\n",
    "\n",
    "\n",
    "def user_user_recs_part2_1(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "    # Your code here\n",
    "    \n",
    "    # list of article ids and article names for input user_id\n",
    "    user_id_article_ids, user_id_article_names = get_user_articles(user_id, user_item=user_item)\n",
    "    user_id_article_ids = [float(i) for i in user_id_article_ids] # converting input user_id article ids to float values\n",
    "    \n",
    "    \n",
    "    # dataframe of most similar users for input user_id \n",
    "    df_top_users = get_top_sorted_users(user_id, df=df, user_item=user_item)\n",
    "    \n",
    "    # getting number of article interactions\n",
    "    num_article_interactions = df.groupby('article_id').count()['user_id']\n",
    "    \n",
    "    # looping through users based on closeness to the input user_id\n",
    "    recs = []\n",
    "    \n",
    "    for index, col in df_top_users.iterrows():\n",
    "        user_article_ids, user_article_names = get_user_articles(col['neighbor id'], user_item=user_item) # getting article ids for each user\n",
    "        user_article_ids = [float(x) for x in user_article_ids] # converting article ids to float values\n",
    "        new_recs = np.setdiff1d(user_article_ids, user_id_article_ids, assume_unique=True) # list of article id values present in user, but not in input user_id\n",
    "        recs_to_add = num_article_interactions.loc[new_recs].sort_values(ascending=False) # sorting list of interactions from highest to lowest value\n",
    "        recs_to_add_list = recs_to_add.index.values.tolist() # creating new recommendations list\n",
    "        [recs.append(x) for x in recs_to_add_list if x not in recs] # creating article id recommendation list with no duplicate article ids\n",
    "    \n",
    "        if len(recs) > m:\n",
    "            break\n",
    "    \n",
    "    recs = recs[:m]\n",
    "    rec_names = get_article_names(recs)\n",
    "\n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_user_recs_part2_2(user_id, m=10):\n",
    "    \n",
    "    df_top_users = get_top_sorted_users(user_id, df=df, user_item=user_item)\n",
    "    num_article_interactions = df.groupby('article_id').count()['user_id']\n",
    "    \n",
    "    recs = []\n",
    "    \n",
    "    for user in df_top_users['neighbor id']:\n",
    "        user_article_ids, user_article_names = get_user_articles(user, user_item)\n",
    "        new_recs = np.setdiff1d(user_article_ids, user_article_names, assume_unique=True)\n",
    "        recs = np.unique(np.concatenate([recs, new_recs], axis=0))\n",
    "        \n",
    "        if len(recs) > m-1:\n",
    "            break\n",
    "    \n",
    "    recs = [float(x) for x in recs]\n",
    "    recs = num_article_interactions.loc[recs].sort_values(ascending=False)\n",
    "    recs.sort_values(ascending=False, inplace=True)\n",
    "    recs = list (recs.index[:m])\n",
    "    \n",
    "    rec_names = get_article_names(recs)\n",
    "    \n",
    "    return recs, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([  12.0,  109.0,  125.0,  142.0,  164.0,  205.0,  302.0,  336.0,\\n               362.0,  465.0,  555.0,  651.0,  681.0,  686.0,  730.0,  761.0,\\n               793.0,  880.0,  911.0,  939.0,  981.0, 1024.0, 1085.0, 1150.0,\\n              1151.0, 1152.0, 1153.0, 1154.0, 1157.0, 1160.0, 1162.0, 1163.0,\\n              1166.0, 1170.0, 1172.0, 1176.0, 1276.0, 1278.0, 1296.0, 1304.0,\\n              1324.0, 1329.0, 1330.0, 1331.0, 1335.0, 1336.0, 1338.0, 1346.0,\\n              1351.0, 1354.0, 1356.0, 1357.0, 1360.0, 1364.0, 1367.0, 1368.0,\\n              1386.0, 1391.0, 1396.0, 1407.0, 1409.0, 1410.0, 1411.0, 1420.0,\\n              1424.0, 1426.0, 1427.0, 1433.0, 1444.0],\\n             dtype='float64', name='article_id')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_user_recs_part2_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 89\u001b[0m, in \u001b[0;36muser_user_recs_part2_1\u001b[0;34m(user_id, m)\u001b[0m\n\u001b[1;32m     87\u001b[0m user_article_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m user_article_ids] \u001b[38;5;66;03m# converting article ids to float values\u001b[39;00m\n\u001b[1;32m     88\u001b[0m new_recs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(user_article_ids, user_id_article_ids, assume_unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# list of article id values present in user, but not in input user_id\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m recs_to_add \u001b[38;5;241m=\u001b[39m \u001b[43mnum_article_interactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_recs\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# sorting list of interactions from highest to lowest value\u001b[39;00m\n\u001b[1;32m     90\u001b[0m recs_to_add_list \u001b[38;5;241m=\u001b[39m recs_to_add\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;66;03m# creating new recommendations list\u001b[39;00m\n\u001b[1;32m     91\u001b[0m [recs\u001b[38;5;241m.\u001b[39mappend(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m recs_to_add_list \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recs] \u001b[38;5;66;03m# creating article id recommendation list with no duplicate article ids\u001b[39;00m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Float64Index([  12.0,  109.0,  125.0,  142.0,  164.0,  205.0,  302.0,  336.0,\\n               362.0,  465.0,  555.0,  651.0,  681.0,  686.0,  730.0,  761.0,\\n               793.0,  880.0,  911.0,  939.0,  981.0, 1024.0, 1085.0, 1150.0,\\n              1151.0, 1152.0, 1153.0, 1154.0, 1157.0, 1160.0, 1162.0, 1163.0,\\n              1166.0, 1170.0, 1172.0, 1176.0, 1276.0, 1278.0, 1296.0, 1304.0,\\n              1324.0, 1329.0, 1330.0, 1331.0, 1335.0, 1336.0, 1338.0, 1346.0,\\n              1351.0, 1354.0, 1356.0, 1357.0, 1360.0, 1364.0, 1367.0, 1368.0,\\n              1386.0, 1391.0, 1396.0, 1407.0, 1409.0, 1410.0, 1411.0, 1420.0,\\n              1424.0, 1426.0, 1427.0, 1433.0, 1444.0],\\n             dtype='float64', name='article_id')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "user_user_recs_part2_1(20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([1024.0, 1085.0,  109.0, 1150.0, 1151.0, 1152.0, 1153.0, 1154.0,\\n              1157.0, 1160.0, 1162.0, 1163.0, 1166.0, 1170.0, 1172.0, 1176.0,\\n                12.0,  125.0, 1276.0, 1278.0, 1296.0, 1304.0, 1324.0, 1329.0,\\n              1330.0, 1331.0, 1335.0, 1336.0, 1338.0, 1346.0, 1351.0, 1354.0,\\n              1356.0, 1357.0, 1360.0, 1364.0, 1367.0, 1368.0, 1386.0, 1391.0,\\n              1396.0, 1407.0, 1409.0, 1410.0, 1411.0,  142.0, 1420.0, 1424.0,\\n              1426.0, 1427.0, 1433.0, 1444.0,  164.0,  205.0,  232.0,  302.0,\\n               336.0,  362.0,  465.0,  555.0,  651.0,  681.0,  686.0,  730.0,\\n               761.0,  793.0,  844.0,  880.0,  911.0,  939.0,  981.0],\\n             dtype='float64', name='article_id')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_user_recs_part2_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 17\u001b[0m, in \u001b[0;36muser_user_recs_part2_2\u001b[0;34m(user_id, m)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     16\u001b[0m recs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m recs]\n\u001b[0;32m---> 17\u001b[0m recs \u001b[38;5;241m=\u001b[39m \u001b[43mnum_article_interactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecs\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m recs\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m recs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m (recs\u001b[38;5;241m.\u001b[39mindex[:m])\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Float64Index([1024.0, 1085.0,  109.0, 1150.0, 1151.0, 1152.0, 1153.0, 1154.0,\\n              1157.0, 1160.0, 1162.0, 1163.0, 1166.0, 1170.0, 1172.0, 1176.0,\\n                12.0,  125.0, 1276.0, 1278.0, 1296.0, 1304.0, 1324.0, 1329.0,\\n              1330.0, 1331.0, 1335.0, 1336.0, 1338.0, 1346.0, 1351.0, 1354.0,\\n              1356.0, 1357.0, 1360.0, 1364.0, 1367.0, 1368.0, 1386.0, 1391.0,\\n              1396.0, 1407.0, 1409.0, 1410.0, 1411.0,  142.0, 1420.0, 1424.0,\\n              1426.0, 1427.0, 1433.0, 1444.0,  164.0,  205.0,  232.0,  302.0,\\n               336.0,  362.0,  465.0,  555.0,  651.0,  681.0,  686.0,  730.0,\\n               761.0,  793.0,  844.0,  880.0,  911.0,  939.0,  981.0],\\n             dtype='float64', name='article_id')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "user_user_recs_part2_2(20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Float64Index([  12.0,  109.0,  125.0,  142.0,  164.0,  205.0,  302.0,  336.0,\\n               362.0,  465.0,  555.0,  651.0,  681.0,  686.0,  730.0,  761.0,\\n               793.0,  880.0,  911.0,  939.0,  981.0, 1024.0, 1085.0, 1150.0,\\n              1151.0, 1152.0, 1153.0, 1154.0, 1157.0, 1160.0, 1162.0, 1163.0,\\n              1166.0, 1170.0, 1172.0, 1176.0, 1276.0, 1278.0, 1296.0, 1304.0,\\n              1324.0, 1329.0, 1330.0, 1331.0, 1335.0, 1336.0, 1338.0, 1346.0,\\n              1351.0, 1354.0, 1356.0, 1357.0, 1360.0, 1364.0, 1367.0, 1368.0,\\n              1386.0, 1391.0, 1396.0, 1407.0, 1409.0, 1410.0, 1411.0, 1420.0,\\n              1424.0, 1426.0, 1427.0, 1433.0, 1444.0],\\n             dtype='float64', name='article_id')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Quick spot check - don't change this code - just use it to test your functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rec_ids, rec_names \u001b[38;5;241m=\u001b[39m \u001b[43muser_user_recs_part2_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe top 10 recommendations for user 20 are the following article ids:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(rec_ids)\n",
      "Cell \u001b[0;32mIn[26], line 89\u001b[0m, in \u001b[0;36muser_user_recs_part2_1\u001b[0;34m(user_id, m)\u001b[0m\n\u001b[1;32m     87\u001b[0m user_article_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m user_article_ids] \u001b[38;5;66;03m# converting article ids to float values\u001b[39;00m\n\u001b[1;32m     88\u001b[0m new_recs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(user_article_ids, user_id_article_ids, assume_unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# list of article id values present in user, but not in input user_id\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m recs_to_add \u001b[38;5;241m=\u001b[39m \u001b[43mnum_article_interactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_recs\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# sorting list of interactions from highest to lowest value\u001b[39;00m\n\u001b[1;32m     90\u001b[0m recs_to_add_list \u001b[38;5;241m=\u001b[39m recs_to_add\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;66;03m# creating new recommendations list\u001b[39;00m\n\u001b[1;32m     91\u001b[0m [recs\u001b[38;5;241m.\u001b[39mappend(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m recs_to_add_list \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recs] \u001b[38;5;66;03m# creating article id recommendation list with no duplicate article ids\u001b[39;00m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m//anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Float64Index([  12.0,  109.0,  125.0,  142.0,  164.0,  205.0,  302.0,  336.0,\\n               362.0,  465.0,  555.0,  651.0,  681.0,  686.0,  730.0,  761.0,\\n               793.0,  880.0,  911.0,  939.0,  981.0, 1024.0, 1085.0, 1150.0,\\n              1151.0, 1152.0, 1153.0, 1154.0, 1157.0, 1160.0, 1162.0, 1163.0,\\n              1166.0, 1170.0, 1172.0, 1176.0, 1276.0, 1278.0, 1296.0, 1304.0,\\n              1324.0, 1329.0, 1330.0, 1331.0, 1335.0, 1336.0, 1338.0, 1346.0,\\n              1351.0, 1354.0, 1356.0, 1357.0, 1360.0, 1364.0, 1367.0, 1368.0,\\n              1386.0, 1391.0, 1396.0, 1407.0, 1409.0, 1410.0, 1411.0, 1420.0,\\n              1424.0, 1426.0, 1427.0, 1433.0, 1444.0],\\n             dtype='float64', name='article_id')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "rec_ids, rec_names = user_user_recs_part2_1(20, 10)\n",
    "print(\"The top 10 recommendations for user 20 are the following article ids:\")\n",
    "print(rec_ids)\n",
    "print()\n",
    "print(\"The top 10 recommendations for user 20 are the following article names:\")\n",
    "print(rec_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "# Find the user that is most similar to user 1 \n",
    "user1_most_sim = get_top_sorted_users(1, df, user_item).iloc[0][0]\n",
    "\n",
    "# Find the 10th most similar user to user 131\n",
    "user131_10th_sim = get_top_sorted_users(131, df, user_item).iloc[9][0] \n",
    "\n",
    "print ('The user that is most similar to user #1:', user1_most_sim)\n",
    "print ('---------------------------------')\n",
    "print ('The user that is the 10th most similar to user #131:', user131_10th_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's would be appropreate to recommend the ids of top 10 articles since we have no information about the new users. Thus, the function of get_top_article_ids(10) would be introduced. The drawback of the solution is that it is a simple recommendation and it does not consider personal preference and relevance. knowledge based or content based recommendation engine could be a feasible solution to the cold start problem.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "\n",
    "# Your recommendations here\n",
    "new_user_recs = get_top_article_ids(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize the text\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenization function: \n",
    "    \n",
    "    Input: raw text\n",
    "    Process: \n",
    "    url replacement\n",
    "    normalized\n",
    "    stop words removed\n",
    "    lemmatized\n",
    "    remove words shorter than 2 letters\n",
    "    \n",
    "    Output: tokenized text\"\"\"\n",
    "    \n",
    "    # replace url with \"urlplaceholder\"\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    \n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    stop_words = stopwords.words(\"english\")\n",
    "       \n",
    "    #tokenize\n",
    "    words = word_tokenize (text)\n",
    "    \n",
    "    #lemmatizing\n",
    "    clean_tokens = [WordNetLemmatizer().lemmatize(w) for w in words if w not in stop_words]\n",
    "    \n",
    "    # remove short words\n",
    "    clean_tokens = [token for token in clean_tokens if len(clean_tokens) > 2]\n",
    "   \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_article_to_user(article_ids, m = 10, df=df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function Description: \n",
    "    Return the recommended titles of articles to the user who are interested in a specific article_id\n",
    "    \n",
    "    Input: \n",
    "    article_ids - (list) a list of the article ids seen by the user \n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    Output: \n",
    "    (list) a list of recommendations for the user by article id\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "     # Remove duplicate rows of 'article_id'\n",
    "    df = df.drop_duplicates('article_id')\n",
    "    \n",
    "    # Create & fit the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer())\n",
    "    ])\n",
    "    \n",
    "    pipeline_matrix = pipeline.fit_transform(df['title'])\n",
    "    \n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_sim =  linear_kernel(pipeline_matrix, pipeline_matrix, True)\n",
    "    \n",
    "    # Construct a reverse map of indices and article titles\n",
    "    indices = pd.Series(df.index, index=df['title']).drop_duplicates()\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    # retrieve matching article title index\n",
    "    title = pd.Series (get_article_names([article_ids]))[0] # Convert the required article id into name of title\n",
    "    if title not in indices.index:\n",
    "        print(\"Article is not in the database.\")\n",
    "        return\n",
    "    else:\n",
    "        idx = indices[title]\n",
    "    \n",
    "    # cosine similarity scores of articles in descending order\n",
    "    scores = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "    \n",
    "    # top m most similar article indexes\n",
    "    # use 1:m because 0 is the same movie entered\n",
    "    top_m_idx = list(scores.iloc[1:m].index)\n",
    "        \n",
    "    return df['title'].iloc[top_m_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Rather than leverage most of the functions created in previous questions, the system of content based recommendation is followed by matrix of cosine similarity. The first step is to create a function of tokenize the text of articles, than fit the pipepline with CountVectorizer and TfidfTransformer into the title of the dataframe.**\n",
    "\n",
    "**2. The function of text preparation includes the process of url replacement, normalization, stop words removal, and lemmatization. Also, only words with more than 2 letters are reserved to avoid too short vocabularies.**\n",
    "\n",
    "**3. The cosine similarity is used to calculate a numeric quantity that denotes the similarity between two articles. It is independant magitude and faster for calculation because of its simpleness. In addition, even if the two similar data items are far apart by the Euclidean distance due of the size, they could still have a smaller angle between them. Smaller the angle, higher the similarity.** \n",
    "\n",
    "**4. Several potential optimization and improvement for this recommendation system could be made. For example, there is no right answer whether the comparizion of cosine similarity is the best solution. Other popular measurement of similarity such as Euclidean Distance or Manhattan Distance could demonstrate a better precise recommendation.** \n",
    "\n",
    "**5. Finally, since brand new users have not read any article yet, any content based recommendation can't be given and thus I've return back the most popuplar articles.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make recommendations for a brand new user\n",
    "new_user_recs = [str(id) for id in get_top_article_ids(10)]\n",
    "print ('Recommendations for a brand new user')\n",
    "print ('-'*60)\n",
    "print(get_article_names(new_user_recs))\n",
    "print ('-'*60)\n",
    "\n",
    "# make 10 recommendations to the user who only has interacted with article id '1427.0'\n",
    "print ('='*60)\n",
    "print ('Top 10 recommendations to the user who only has interacted with article id \"1427.0\"')\n",
    "print ('-'*60)\n",
    "print (recommend_article_to_user('1427.0'))\n",
    "print ('-'*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "\n",
    "u, s, vt = np.linalg.svd(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The advantage of FunkSVD is to avoid errors from the missing values; however, since the item matrix is composed of ones and zeros without any NaN, the tradintional SVD method is adopt our case**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "    \n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs)/df.shape[0]);\n",
    "plt.xlabel('Number of Latent Features');\n",
    "plt.ylabel('Accuracy');\n",
    "plt.title('Accuracy vs. Number of Latent Features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    # User-item matrix of the training df\n",
    "    user_item_train = create_user_item_matrix (df_train)\n",
    "    \n",
    "    # User-item matrix of the testting df\n",
    "    user_item_test = create_user_item_matrix (df_test)\n",
    "\n",
    "    # Find users both in test and in train\n",
    "    train_idx = set(user_item_train.index)\n",
    "    test_idx = set(user_item_test.index)\n",
    "    common_idx = train_idx.intersection(test_idx)\n",
    "    \n",
    "    # Find articles both in test and in train\n",
    "    train_arts = set(user_item_train.columns)\n",
    "    test_arts = set(user_item_test.columns)\n",
    "    common_cols = train_arts.intersection(test_arts)\n",
    "\n",
    "\n",
    "    user_item_test = user_item_test.loc[common_idx, common_cols]\n",
    "    \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n",
    "\n",
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many users can we make predictions for in the test set?\n",
    "user_item_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many users in the test set are we not able to make predictions for because of the cold start problem?\n",
    "len(test_idx) - user_item_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many articles can we make predictions for in the test set?\n",
    "user_item_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many articles in the test set are we not able to make predictions for because of the cold start problem?\n",
    "len(test_arts) - user_item_test.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': c , \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': a, \n",
    "    'How many articles can we make predictions for in the test set?': b,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?':d,\n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit SVD on the user_item_train matrix\n",
    "u_train, s_train, vt_train = np.linalg.svd(user_item_train, full_matrices=False )\n",
    "print (s_train.shape, u_train.shape, vt_train.shape, user_item_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "row_idxs = user_item_train.index.isin(test_idx)\n",
    "col_idxs = user_item_train.columns.isin(test_arts)\n",
    "u_test = u_train[row_idxs, :]\n",
    "vt_test = vt_train[:, col_idxs]\n",
    "\n",
    "#num_latent_feats = np.arange(0, 700+10, 20)\n",
    "num_latent_feats = np.arange(5, 500, 10)\n",
    "sum_errs_train = []\n",
    "sum_errs_test = []\n",
    "#all_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_train_lat, u_train_lat, vt_train_lat = np.diag(s_train[:k]), u_train[:, :k], vt_train[:k, :]\n",
    "    u_test_lat, vt_test_lat = u_test[:, :k], vt_test[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_train_estimate = np.around(np.dot(np.dot(u_train_lat, s_train_lat), vt_train_lat))\n",
    "    user_item_test_estimate = np.around(np.dot(np.dot(u_test_lat, s_train_lat), vt_test_lat))\n",
    "    #all_errs.append(1 - ((np.sum(user_item_test_estimate)+np.sum(np.sum(user_item_test)))/(user_item_test.shape[0]*user_item_test.shape[1])))\n",
    "    \n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs_train = np.subtract(user_item_train, user_item_train_estimate)\n",
    "    diffs_test = np.subtract(user_item_test, user_item_test_estimate)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err_train = np.sum(np.sum(np.abs(diffs_train)))\n",
    "    err_test = np.sum(np.sum(np.abs(diffs_test)))\n",
    "    \n",
    "    sum_errs_train.append(err_train)\n",
    "    sum_errs_test.append(err_test)\n",
    "    \n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs_train)/(user_item_train.shape[0]*user_item_test.shape[1]), label='Train', color='r');\n",
    "plt.plot(num_latent_feats, 1 - np.array(sum_errs_test)/(user_item_test.shape[0]*user_item_test.shape[1]), label='Test', color='c');\n",
    "#plt.plot(num_latent_feats, all_errs, label='All Data')\n",
    "plt.xlabel('Number of Latent Features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Number of Latent Features')\n",
    "plt.legend()\n",
    "plt.savefig('Accuracy vs. Number of Latent Features.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explained_variance(sigma, n_components):\n",
    "    \"\"\"\n",
    "    Computes explained variance number of components\n",
    "    \"\"\"\n",
    "    # percentage of variance explained\n",
    "    total_var = np.sum(sigma**2)\n",
    "    var_exp = np.sum([np.square(i) for i in sigma[:n_components]])\n",
    "    perc_exp = (var_exp / total_var) * 100\n",
    "    return round(perc_exp, 4)\n",
    "\n",
    "explained_variance(s_train, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. The accuracy reaches around 100% when the number of latent features is at approximately 300. In generaly, the accuracy of training data is above 99%, and it increases while the number of latent features expands, which indicates overfitting in training dataset.** <br>\n",
    "\n",
    "**2. On. the contrary, the accuracy of test data reduces during the enlarging quantity of latent features. The accuracy maintains at around 96% when the latent features is more than 300.** <br>\n",
    "\n",
    "**3. At first glance, the level of accuracy is quite promising; however, the classes in the dataset is quite imbalance, and there are only 20 users in the testing dataset. Thus, the result of prediction would be biased.** <br>\n",
    "\n",
    "**4. When the number of latent features is set as 300, 92.0776% of variance is explained in this model.**\n",
    "\n",
    "**5. In addition, there are several methods could be considered regarding to the improvement of the recommendation system:** <br>\n",
    "> **a. A simple feedback could be used as a straight rating system. For instance, a variable could be used by \"Like\" or \"Dislike\" after the article is read. Such binary response would be helpful to identify whether the articles cater to users' preferences.** <br>\n",
    "\n",
    "> **b. The instant interactions among users and articles could be an online measurement of performance. If the interactions increased after a article is released, it would indicate the recommendation and satisfacetion is improved.** <br>\n",
    "\n",
    "> **c. A/B testing would also be performed. The data could be analyed whether the results supports our hypothesis. Further experiment could be conducted to determine if a certain of new recommendations lead to any significant improvement of interactions.**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> **An obvious trend can be observed that the accuracy related to the training data tends to increase when the latent features rises. On the other hand, the accuracy associated with the test data reveals the opposite movement. The difference would be due to the lack of users shared in training and testing data, since only 20 users are found in the test data, which would be insufficient to lead a solid result of estimation to actual values.**<br>\n",
    "\n",
    "> **It's hard to jump into conclusion that SVD is a reliable recommendation engine in this project. Clearly, the dataset is quite limited. Compared to rating-type system, binary oriented (with 1s and 0s) dataset is more likely to demonstrate imbalanced interactions among users and items (such as articles in this case). Additional recommendation agorithems could be applied. Moreover, there are few possible experiments could improve the recommendation system. For example, online measurement of performance monitoring interactions among users and articles; or observe whether the data analysis supports the hypothesis in the A/B testing.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
